{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63a496cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1d23239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\user\\anaconda3\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\user\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c319f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a21e9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/crop_data_pivot.csv\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Define target columns (each \"Element\")\n",
    "elements = [\"Production\", \"Area harvested\", \"Yield\"]\n",
    "\n",
    "# Define features to use — here we only use 'Year'\n",
    "#feature_cols = [\"Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9ecbd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Area', 'Item', 'Year', 'Area harvested', 'Production', 'Yield']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1a59d4",
   "metadata": {},
   "source": [
    "Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e8c3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef get_models():\\n    return {\\n        \"LinearRegression\": LinearRegression(),\\n        \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\\n        \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\\n        \"ANN\": Sequential([\\n            Dense(64, input_dim=len(feature_cols), activation=\\'relu\\'),\\n            Dense(32, activation=\\'relu\\'),\\n            Dense(1)\\n        ])\\n    }\\n    '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def get_models():\n",
    "    return {\n",
    "        \"LinearRegression\": LinearRegression(),\n",
    "        \"RandomForest\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42),\n",
    "        \"ANN\": Sequential([\n",
    "            Dense(64, input_dim=len(feature_cols), activation='relu'),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1)\n",
    "        ])\n",
    "    }\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8843ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\ndef train_ann(X_train, y_train, X_test, y_test, model_path):\\n    model = Sequential()\\n    model.add(Dense(32, input_dim=X_train.shape[1], activation=\\'relu\\'))\\n    model.add(Dense(16, activation=\\'relu\\'))\\n    model.add(Dense(1))\\n    model.compile(optimizer=\\'adam\\', loss=MeanSquaredError())\\n    model.fit(X_train, y_train, epochs=50, batch_size=64, verbose=0)\\n    y_pred = model.predict(X_test).flatten()\\n    model.save(f\"{model_path}.h5\")\\n    return y_pred, model\\n    '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper function: train ANN\n",
    "\"\"\"\"\n",
    "def train_ann(X_train, y_train, X_test, y_test, model_path):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss=MeanSquaredError())\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=64, verbose=0)\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    model.save(f\"{model_path}.h5\")\n",
    "    return y_pred, model\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "641b3e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\\ndef train_ann(X_train, y_train, X_test, y_test, model_path):\\n    model = Sequential()\\n    model.add(Dense(64, input_dim=X_train.shape[1], activation=\\'relu\\'))\\n    model.add(Dropout(0.1))\\n\\n    model.add(Dense(32, activation=\\'relu\\'))\\n    model.add(Dropout(0.1))\\n\\n    model.add(Dense(16, activation=\\'relu\\'))\\n    model.add(Dropout(0.1))\\n\\n    model.add(Dense(1))\\n    \\n    model.compile(optimizer=\\'adam\\', loss=MeanSquaredError())\\n    \\n    es = EarlyStopping(monitor=\\'val_loss\\', patience=10, restore_best_weights=True)\\n\\n    model.fit(X_train, y_train, \\n              validation_split=0.2, \\n              epochs=50, \\n              batch_size=64, \\n              callbacks=[es], \\n              verbose=0)\\n    \\n    y_pred = model.predict(X_test).flatten()\\n    model.save(f\"{model_path}.h5\")\\n    return y_pred, model\\n    '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from tensorflow.keras.layers import Dropout, LeakyReLU\n",
    "\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "\"\"\"\"\n",
    "def train_ann(X_train, y_train, X_test, y_test, model_path):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=MeanSquaredError())\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train, \n",
    "              validation_split=0.2, \n",
    "              epochs=50, \n",
    "              batch_size=64, \n",
    "              callbacks=[es], \n",
    "              verbose=0)\n",
    "    \n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    model.save(f\"{model_path}.h5\")\n",
    "    return y_pred, model\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edac1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "def train_ann(X_train, y_train, X_test, y_test, model_path):\n",
    "    input_layer = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(64, activation='relu')(input_layer)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    output = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss=MeanSquaredError())\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              validation_split=0.2,\n",
    "              epochs=50,\n",
    "              batch_size=64,\n",
    "              callbacks=[es],\n",
    "              verbose=0)\n",
    "\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    model.save(f\"{model_path}.h5\")  # ✅ Save in .h5 format\n",
    "    return y_pred, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97459935",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f08e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Training models for: Production\n",
      "🔹 Training ANN...\n",
      "\u001b[1m3599/3599\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 474us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training Random Forest...\n",
      "🔹 Training Linear Regression...\n",
      "🔹 Training XGBoost...\n",
      "✅ All models for Production saved.\n",
      "\n",
      "📌 Training models for: Area harvested\n",
      "🔹 Training ANN...\n",
      "\u001b[1m3599/3599\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 502us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training Random Forest...\n",
      "🔹 Training Linear Regression...\n",
      "🔹 Training XGBoost...\n",
      "✅ All models for Area harvested saved.\n",
      "\n",
      "📌 Training models for: Yield\n",
      "🔹 Training ANN...\n",
      "\u001b[1m3599/3599\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 480us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Training Random Forest...\n",
      "🔹 Training Linear Regression...\n",
      "🔹 Training XGBoost...\n",
      "✅ All models for Yield saved.\n"
     ]
    }
   ],
   "source": [
    "# Loop each element\n",
    "for element in elements:\n",
    "    print(f\"\\n📌 Training models for: {element}\")\n",
    "\n",
    "    # Define features dynamically\n",
    "    feature_cols = [col for col in elements if col != element] + [\"Year\"]\n",
    "    \n",
    "    # Drop rows where *either* the target OR any feature is missing\n",
    "    data = df.dropna(subset=[element] + feature_cols).copy()\n",
    "    X = data[feature_cols]\n",
    "    y = data[element]\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # === Train ANN ===\n",
    "    print(\"🔹 Training ANN...\")\n",
    "    y_pred_ann, model_ann = train_ann(X_train, y_train, X_test, y_test, f\"models/{element}_ANN\")\n",
    "    joblib.dump(scaler, f\"models/{element}_ANN_scaler.pkl\", compress=3)\n",
    "\n",
    "    # === Train Random Forest ===\n",
    "    print(\"🔹 Training Random Forest...\")\n",
    "    rf = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    joblib.dump({\"model\": rf, \"scaler\": scaler}, f\"models/{element}_RandomForest.pkl\", compress=3)\n",
    "\n",
    "    # === Train Linear Regression ===\n",
    "    print(\"🔹 Training Linear Regression...\")\n",
    "    #poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    #X_poly = poly.fit_transform(X_scaled)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    joblib.dump({\"model\": lr, \"scaler\": scaler}, f\"models/{element}_LinearRegression.pkl\")\n",
    "\n",
    "    # === Train XGBoost ===\n",
    "    print(\"🔹 Training XGBoost...\")\n",
    "    xg = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "    \"\"\"\n",
    "    xg = xgb.XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42\n",
    "    )\n",
    "    \"\"\"\n",
    "    xg.fit(X_train, y_train)\n",
    "    joblib.dump({\"model\": xg, \"scaler\": scaler}, f\"models/{element}_XGBoost.pkl\")\n",
    "\n",
    "    print(\"✅ All models for\", element, \"saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
